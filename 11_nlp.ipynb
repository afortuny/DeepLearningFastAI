{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afortuny/DeepLearningFastAI/blob/main/11_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Kzn8OTbthOpl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50092554-2083-49d9-98e0-27091c21f34a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 719 kB 9.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 55.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 57.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 362 kB 80.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 77.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 78.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 60.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 13.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 71.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 75.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 75.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 77.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 64.6 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#hide\n",
        "! [ -e /content ] && pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cq9odkmjhOp1"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "from fastbook import *\n",
        "from IPython.display import display,HTML\n",
        "from fastai.text.all import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuuSV4O7hOqJ"
      },
      "source": [
        "# Transfer learning on text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to be able to use unstructured text for a downstream task, we can leverage a pretrained model on massive amounts of text instead of starting from scratch. The models use to encode multiple aspects of language and text in general are called language models."
      ],
      "metadata": {
        "id": "JEppBUK87BFy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1B8e_yRhOqP"
      },
      "source": [
        "\n",
        "\n",
        "What we call a language model is a model that has been trained to guess what the next word in a text is (having read the ones before). This kind of task is called *self-supervised learning*: we do not need to give labels to our model, just feed it lots and lots of texts. It has a process to automatically get labels from the data, and this task isn't trivial: to properly guess the next word in a sentence, the model will have to develop an understanding of the English (or other) language. Self-supervised learning can also be used in other domains; for instance, see [\"Self-Supervised Learning and Computer Vision\"](https://www.fast.ai/2020/01/13/self_supervised/) for an introduction to vision applications. Self-supervised learning is not usually used for the model that is trained directly, but instead is used for pretraining a model used for transfer learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITlY9-hthOqU"
      },
      "source": [
        "> jargon: Self-supervised learning: Training a model using labels that are embedded in the independent variable, rather than requiring external labels. For instance, training a model to predict the next word in a text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1Qm2W8OhOqW"
      },
      "source": [
        "The pretrained language model we will used here was pretrained on Wikipedia. We can get great results by directly fine-tuning this language model to our downstream task, but with one extra step, we can do even better. The Wikipedia English is slightly different from language used in your specific application, so instead of jumping directly to the classifier, we could fine-tune our pretrained language model our own corpus and then use *that* as the base for our downstream task.\n",
        "\n",
        "Even if our language model knows the basics of the language we are using in the task (e.g., our pretrained model is in English), it helps to get used to the style of the corpus we are targeting. It may be more informal language, or more technical, with new words to learn or different ways of composing sentences. \n",
        "\n",
        "This is known as the Universal Language Model Fine-tuning (ULMFit) approach. The [paper](https://arxiv.org/abs/1801.06146) showed that this extra stage of fine-tuning of the language model, prior to transfer learning to a classification task, resulted in significantly better predictions. Using this approach, we have three stages for transfer learning in NLP, as summarized here:."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ2WJK8vhOqc"
      },
      "source": [
        "<img alt=\"Diagram of the ULMFiT process\" width=\"700\" caption=\"The ULMFiT process\" id=\"ulmfit_process\" src=\"https://github.com/fastai/fastbook/blob/master/images/att_00027.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj7c1b9ohOqj"
      },
      "source": [
        "## Text Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKA4lU3XhOql"
      },
      "source": [
        "It's not at all obvious how we're going to use what we've learned so far to build a language model. Sentences can be different lengths, and documents can be very long. So, how can we predict the next word of a sentence using a neural network? Let's find out!\n",
        "\n",
        "We've already seen how categorical variables can be used as independent variables for a neural network ([categorical embeddings]([https://alanfortunysicart.blogspot.com/2022/07/fastai-deep-learning-journey-part-10.html)). \n",
        "\n",
        "We can do nearly the same thing with text! What is new is the idea of a sequence. First we concatenate all of the documents in our dataset into one big long string and split it into words, giving us a very long list of words (or \"tokens\"). Our independent variable will be the sequence of words starting with the first word in our very long list and ending with the second to last, and our dependent variable will be the sequence of words starting with the second word and ending with the last word. \n",
        "\n",
        "Our vocab will consist of a mix of common words that are already in the vocabulary of our pretrained model and new words specific to our corpus. Our embedding matrix will be built accordingly: for words that are in the vocabulary of our pretrained model, we will take the corresponding row in the embedding matrix of the pretrained model; but for new words we won't have anything, so we will just initialize the corresponding row with a random vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L91emk9thOqz"
      },
      "source": [
        "### Word Tokenization with fastai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3K_X33khOq1"
      },
      "source": [
        "Rather than providing its own tokenizers, fastai instead provides a consistent interface to a range of tokenizers in external libraries. Tokenization is an active field of research, and new and improved tokenizers are coming out all the time, so the defaults that fastai uses change too. However, the API and options shouldn't change too much, since fastai tries to maintain a consistent API even as the underlying technology changes.\n",
        "\n",
        "Let's try it out with the good reads data set [good books dataset](https://www.kaggle.com/datasets/meetnaren/goodreads-best-books) containing book descriptions and ratings:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib \n",
        "path = pathlib.Path('/content/gdrive/MyDrive/NLP/')"
      ],
      "metadata": {
        "id": "fPmhgt8YRIVm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip '/content/gdrive/MyDrive/NLP/book_data.csv (2).zip' -d '/content/gdrive/MyDrive/NLP'"
      ],
      "metadata": {
        "id": "7JJwn_tetSWY",
        "outputId": "4a661db9-7dcc-46f2-864a-8e8fa3511879",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/gdrive/MyDrive/NLP/book_data.csv (2).zip\n",
            "  inflating: /content/gdrive/MyDrive/NLP/book_data.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the labels\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/NLP/book_data.csv')"
      ],
      "metadata": {
        "id": "od7UvHrutcaB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keep only the description and rating\n",
        "df = df[['book_desc','book_rating']]"
      ],
      "metadata": {
        "id": "enicyixyX_bq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop na recors\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "00byCw6HYkad"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#validate same amount of complete records\n",
        "df.count()"
      ],
      "metadata": {
        "id": "-YF-LnAiYT51",
        "outputId": "14664e3d-324c-4114-d4cd-e2268951ea70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "book_desc      52970\n",
              "book_rating    52970\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As this data set contains multiple languages, the following code filter out the ones in english"
      ],
      "metadata": {
        "id": "ngMjbR5U-lds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# install and import languague detector\n",
        "!pip install langdetect\n",
        "from langdetect import detect"
      ],
      "metadata": {
        "id": "X8WFTBqPtspp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# detect english descriptions and keep only those\n",
        "def detect_en(text):\n",
        "    try:\n",
        "        return detect(text) == 'en'\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "df = df[df['book_desc'].apply(detect_en)]"
      ],
      "metadata": {
        "id": "o6dKII4DxkUv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the data frame after processing, as language detect take a few min"
      ],
      "metadata": {
        "id": "I0HX5HOW-tti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df.to_pickle(\"/content/gdrive/MyDrive/NLP/english_books.pkl\")"
      ],
      "metadata": {
        "id": "7Qz4Xn6Nq59T"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_pickle(\"/content/gdrive/MyDrive/NLP/english_books.pkl\")"
      ],
      "metadata": {
        "id": "S7uJTyzKt1D5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWwbJEQghOrL"
      },
      "source": [
        "As we write this post, the default English word tokenizer for fastai uses a library called *spaCy*. It has a sophisticated rules engine with special rules for URLs, individual special English words, and much more. Rather than directly using `SpacyTokenizer`, however, we'll use `WordTokenizer`, since that will always point to fastai's current default word tokenizer (which may not necessarily be spaCy, depending when you're reading this)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = df.loc[0,'book_desc'][:50]"
      ],
      "metadata": {
        "id": "NqF0kUwZ1N-z"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mZxWW4whOrN",
        "outputId": "c32600b1-dae6-4dfd-e3c9-74685a16717e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(#9) ['Winning','will','make','you','famous','.','Losing','means','certain']\n"
          ]
        }
      ],
      "source": [
        "spacy = WordTokenizer()\n",
        "toks = first(spacy([txt]))\n",
        "print(coll_repr(toks, 30))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1txpH5O0hOrO"
      },
      "source": [
        "As you see, spaCy has mainly just separated out the words and punctuation. But it does something else here too: it has split \"it's\" into \"it\" and \"'s\". That makes intuitive sense; these are separate words, really. Tokenization is a surprisingly subtle task, when you think about all the little details that have to be handled. Fortunately, spaCy handles these pretty well for us—for instance, here we see that \".\" is separated when it terminates a sentence, but not in an acronym or number:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRoQQBA4hOrZ"
      },
      "source": [
        "fastai then adds some additional functionality to the tokenization process with the `Tokenizer` class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NP7b_sNIhOra",
        "outputId": "d2695738-9fb4-4dc6-c2a5-97bd858d77a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(#12) ['xxbos','xxmaj','winning','will','make','you','famous','.','xxmaj','losing','means','certain']\n"
          ]
        }
      ],
      "source": [
        "tkn = Tokenizer(spacy)\n",
        "print(coll_repr(tkn(txt), 31))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNCgYXYahOrc"
      },
      "source": [
        "Notice that there are now some tokens that start with the characters \"xx\", which is not a common word prefix in English. These are *special tokens*.\n",
        "\n",
        "For example, the first item in the list, `xxbos`, is a special token that indicates the start of a new text (\"BOS\" is a standard NLP acronym that means \"beginning of stream\"). By recognizing this start token, the model will be able to learn it needs to \"forget\" what was said previously and focus on upcoming words.\n",
        "\n",
        "These special tokens don't come from spaCy directly. They are there because fastai adds them by default, by applying a number of rules when processing text. These rules are designed to make it easier for a model to recognize the important parts of a sentence. In a sense, we are translating the original English language sequence into a simplified tokenized language—a language that is designed to be easy for a model to learn.\n",
        "\n",
        "Here are some of the main special tokens you'll see:\n",
        "\n",
        "- `xxbos`:: Indicates the beginning of a text (here, a review)\n",
        "- `xxmaj`:: Indicates the next word begins with a capital (since we lowercased everything)\n",
        "- `xxunk`:: Indicates the word is unknown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PUAKwtehOrt"
      },
      "source": [
        "### Numericalization with fastai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ibKNKNkhOru"
      },
      "source": [
        "*Numericalization* is the process of mapping tokens to integers. The steps are basically identical to those necessary to create a `Category` variable, such as the dependent variable of digits in MNIST:\n",
        "\n",
        "1. Make a list of all possible levels of that categorical variable (the vocab).\n",
        "1. Replace each level with its index in the vocab.\n",
        "\n",
        "Let's take a look at this in action on the word-tokenized text we saw earlier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "569VqVdahOru",
        "outputId": "942b9117-d9b5-477b-cb98-c1c87c79dbec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(#12) ['xxbos','xxmaj','winning','will','make','you','famous','.','xxmaj','losing','means','certain']\n"
          ]
        }
      ],
      "source": [
        "toks = tkn(txt)\n",
        "print(coll_repr(tkn(txt), 31))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ieg2wGmhOrv"
      },
      "source": [
        "Just like with `SubwordTokenizer`, we need to call `setup` on `Numericalize`; this is how we create the vocab. That means we'll need our tokenized corpus first. Since tokenization takes a while, it's done in parallel by fastai; but for this manual walkthrough, we'll use a small subset:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txts = df.loc[:2000,'book_desc']"
      ],
      "metadata": {
        "id": "dWmUlMv_2D7a"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymH5iw5qhOrv",
        "outputId": "bba146b6-5719-4da9-8007-7ddc3011a7d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#244) ['xxbos','xxmaj','winning','will','make','you','famous','.','xxmaj','losing'...]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "toks200 = txts[:200].map(tkn)\n",
        "toks200[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icm8BBa3hOrw"
      },
      "source": [
        "We can pass this to `setup` to create our vocab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "8DXFbyDlhOrx",
        "outputId": "1fe9bb89-a02d-4104-c1ff-5d2596adc68b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"(#1608) ['xxunk','xxpad','xxbos','xxeos','xxfld','xxrep','xxwrep','xxup','xxmaj',',','the','and','of','.','a','to','in','is','-','his'...]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "num = Numericalize()\n",
        "num.setup(toks200)\n",
        "coll_repr(num.vocab,20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be1X7VwdhOry"
      },
      "source": [
        "Our special rules tokens appear first, and then every word appears once, in frequency order. The defaults to `Numericalize` are `min_freq=3,max_vocab=60000`. `max_vocab=60000` results in fastai replacing all words other than the most common 60,000 with a special *unknown word* token, `xxunk`. This is useful to avoid having an overly large embedding matrix, since that can slow down training and use up too much memory, and can also mean that there isn't enough data to train useful representations for rare words. However, this last issue is better handled by setting `min_freq`; the default `min_freq=3` means that any word appearing less than three times is replaced with `xxunk`.\n",
        "\n",
        "fastai can also numericalize your dataset using a vocab that you provide, by passing a list of words as the `vocab` parameter.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nums = num(toks)[:20]; nums"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1nq_ByAAKZ1",
        "outputId": "ee95cec8-1522-4825-c664-9dfdb567f94b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorText([  2,   8, 283,  52, 190,  79, 247,  13,   8, 854, 664, 855])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6DlL12qhOr2"
      },
      "source": [
        "Now that we have numbers, we need to put them in batches for our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aICVzVfehOr2"
      },
      "source": [
        "### Putting Our Texts into Batches for a Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPmpJLethOr3"
      },
      "source": [
        "When dealing with images, we needed to resize them all to the same height and width before grouping them together in a mini-batch so they could stack together efficiently in a single tensor. Here it's going to be a little different, because one cannot simply resize text to a desired length. Also, we want our language model to read text in order, so that it can efficiently predict what the next word is. This means that each new batch should begin precisely where the previous one left off.\n",
        "\n",
        "Suppose we have the following text:\n",
        "\n",
        "> : In this chapter, we will go back over the example of classifying movie reviews we studied in chapter 1 and dig deeper under the surface. First we will look at the processing steps necessary to convert text into numbers and how to customize it. By doing this, we'll have another example of the PreProcessor used in the data block API.\\nThen we will study how we build a language model and train it for a while.\n",
        "\n",
        "The tokenization process will add special tokens and deal with punctuation to return this text:\n",
        "\n",
        "> : xxbos xxmaj in this chapter , we will go back over the example of classifying movie reviews we studied in chapter 1 and dig deeper under the surface . xxmaj first we will look at the processing steps necessary to convert text into numbers and how to customize it . xxmaj by doing this , we 'll have another example of the preprocessor used in the data block xxup api . \\n xxmaj then we will study how we build a language model and train it for a while .\n",
        "\n",
        "We now have 90 tokens, separated by spaces. Let's say we want a batch size of 6. We need to break this text into 6 contiguous parts of length 15:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "hide_input": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "Vr3DapOBhOr4",
        "outputId": "5af057d0-1fb9-49a8-ea71-ac46674c30af"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>in</td>\n",
              "      <td>this</td>\n",
              "      <td>chapter</td>\n",
              "      <td>,</td>\n",
              "      <td>we</td>\n",
              "      <td>will</td>\n",
              "      <td>go</td>\n",
              "      <td>back</td>\n",
              "      <td>over</td>\n",
              "      <td>the</td>\n",
              "      <td>example</td>\n",
              "      <td>of</td>\n",
              "      <td>classifying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>movie</td>\n",
              "      <td>reviews</td>\n",
              "      <td>we</td>\n",
              "      <td>studied</td>\n",
              "      <td>in</td>\n",
              "      <td>chapter</td>\n",
              "      <td>1</td>\n",
              "      <td>and</td>\n",
              "      <td>dig</td>\n",
              "      <td>deeper</td>\n",
              "      <td>under</td>\n",
              "      <td>the</td>\n",
              "      <td>surface</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>first</td>\n",
              "      <td>we</td>\n",
              "      <td>will</td>\n",
              "      <td>look</td>\n",
              "      <td>at</td>\n",
              "      <td>the</td>\n",
              "      <td>processing</td>\n",
              "      <td>steps</td>\n",
              "      <td>necessary</td>\n",
              "      <td>to</td>\n",
              "      <td>convert</td>\n",
              "      <td>text</td>\n",
              "      <td>into</td>\n",
              "      <td>numbers</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>how</td>\n",
              "      <td>to</td>\n",
              "      <td>customize</td>\n",
              "      <td>it</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>by</td>\n",
              "      <td>doing</td>\n",
              "      <td>this</td>\n",
              "      <td>,</td>\n",
              "      <td>we</td>\n",
              "      <td>'ll</td>\n",
              "      <td>have</td>\n",
              "      <td>another</td>\n",
              "      <td>example</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>of</td>\n",
              "      <td>the</td>\n",
              "      <td>preprocessor</td>\n",
              "      <td>used</td>\n",
              "      <td>in</td>\n",
              "      <td>the</td>\n",
              "      <td>data</td>\n",
              "      <td>block</td>\n",
              "      <td>xxup</td>\n",
              "      <td>api</td>\n",
              "      <td>.</td>\n",
              "      <td>\\n</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>then</td>\n",
              "      <td>we</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>will</td>\n",
              "      <td>study</td>\n",
              "      <td>how</td>\n",
              "      <td>we</td>\n",
              "      <td>build</td>\n",
              "      <td>a</td>\n",
              "      <td>language</td>\n",
              "      <td>model</td>\n",
              "      <td>and</td>\n",
              "      <td>train</td>\n",
              "      <td>it</td>\n",
              "      <td>for</td>\n",
              "      <td>a</td>\n",
              "      <td>while</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#hide_input\n",
        "stream = \"In this chapter, we will go back over the example of classifying movie reviews we studied in chapter 1 and dig deeper under the surface. First we will look at the processing steps necessary to convert text into numbers and how to customize it. By doing this, we'll have another example of the PreProcessor used in the data block API.\\nThen we will study how we build a language model and train it for a while.\"\n",
        "tokens = tkn(stream)\n",
        "bs,seq_len = 6,15\n",
        "d_tokens = np.array([tokens[i*seq_len:(i+1)*seq_len] for i in range(bs)])\n",
        "dfs = pd.DataFrame(d_tokens)\n",
        "display(HTML(dfs.to_html(index=False,header=None)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFtTg-fchOr5"
      },
      "source": [
        "In a perfect world, we could then give this one batch to our model. But that approach doesn't scale, because outside of this toy example it's unlikely that a single batch containing all the texts would fit in our GPU memory (here we have 90 tokens, but all the IMDb reviews together give several million).\n",
        "\n",
        "So, we need to divide this array more finely into subarrays of a fixed sequence length. It is important to maintain order within and across these subarrays, because we will use a model that maintains a state so that it remembers what it read previously when predicting what comes next. \n",
        "\n",
        "Going back to our previous example with 6 batches of length 15, if we chose a sequence length of 5, that would mean we first feed the following array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "hide_input": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "Za4Zy15ohOr5",
        "outputId": "d52f280f-3be4-4ab5-b13c-96742a378351"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>in</td>\n",
              "      <td>this</td>\n",
              "      <td>chapter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>movie</td>\n",
              "      <td>reviews</td>\n",
              "      <td>we</td>\n",
              "      <td>studied</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>first</td>\n",
              "      <td>we</td>\n",
              "      <td>will</td>\n",
              "      <td>look</td>\n",
              "      <td>at</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>how</td>\n",
              "      <td>to</td>\n",
              "      <td>customize</td>\n",
              "      <td>it</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>of</td>\n",
              "      <td>the</td>\n",
              "      <td>preprocessor</td>\n",
              "      <td>used</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>will</td>\n",
              "      <td>study</td>\n",
              "      <td>how</td>\n",
              "      <td>we</td>\n",
              "      <td>build</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#hide_input\n",
        "bs,seq_len = 6,5\n",
        "d_tokens = np.array([tokens[i*15:i*15+seq_len] for i in range(bs)])\n",
        "dfs = pd.DataFrame(d_tokens)\n",
        "display(HTML(dfs.to_html(index=False,header=None)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3iomSHnhOr6"
      },
      "source": [
        "Then this one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "hide_input": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "PfkXK4aQhOr7",
        "outputId": "be95275e-714f-40b5-d9fc-259b7657adfe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>,</td>\n",
              "      <td>we</td>\n",
              "      <td>will</td>\n",
              "      <td>go</td>\n",
              "      <td>back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>chapter</td>\n",
              "      <td>1</td>\n",
              "      <td>and</td>\n",
              "      <td>dig</td>\n",
              "      <td>deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>the</td>\n",
              "      <td>processing</td>\n",
              "      <td>steps</td>\n",
              "      <td>necessary</td>\n",
              "      <td>to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxmaj</td>\n",
              "      <td>by</td>\n",
              "      <td>doing</td>\n",
              "      <td>this</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>the</td>\n",
              "      <td>data</td>\n",
              "      <td>block</td>\n",
              "      <td>xxup</td>\n",
              "      <td>api</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>a</td>\n",
              "      <td>language</td>\n",
              "      <td>model</td>\n",
              "      <td>and</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#hide_input\n",
        "bs,seq_len = 6,5\n",
        "d_tokens = np.array([tokens[i*15+seq_len:i*15+2*seq_len] for i in range(bs)])\n",
        "dfs = pd.DataFrame(d_tokens)\n",
        "display(HTML(dfs.to_html(index=False,header=None)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88Lq_5LPhOr8"
      },
      "source": [
        "And finally:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "hide_input": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "X3ej54K3hOr8",
        "outputId": "62638285-c910-4b48-c731-1adea97da6d5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>over</td>\n",
              "      <td>the</td>\n",
              "      <td>example</td>\n",
              "      <td>of</td>\n",
              "      <td>classifying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>under</td>\n",
              "      <td>the</td>\n",
              "      <td>surface</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>convert</td>\n",
              "      <td>text</td>\n",
              "      <td>into</td>\n",
              "      <td>numbers</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>we</td>\n",
              "      <td>'ll</td>\n",
              "      <td>have</td>\n",
              "      <td>another</td>\n",
              "      <td>example</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>.</td>\n",
              "      <td>\\n</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>then</td>\n",
              "      <td>we</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>it</td>\n",
              "      <td>for</td>\n",
              "      <td>a</td>\n",
              "      <td>while</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#hide_input\n",
        "bs,seq_len = 6,5\n",
        "d_tokens = np.array([tokens[i*15+10:i*15+15] for i in range(bs)])\n",
        "dfs = pd.DataFrame(d_tokens)\n",
        "display(HTML(dfs.to_html(index=False,header=None)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaOdRBFZhOr9"
      },
      "source": [
        "The first step in our dataset will be to transform the individual texts into a stream by concatenating them together. \n",
        "\n",
        "We then cut this stream into a certain number of batches (which is our *batch size*). For instance, if the stream has 50,000 tokens and we set a batch size of 10, this will give us 10 mini-streams of 5,000 tokens. What is important is that we preserve the order of the tokens (so from 1 to 5,000 for the first mini-stream, then from 5,001 to 10,000...), because we want the model to read continuous rows of text (as in the preceding example). An `xxbos` token is added at the start of each during preprocessing, so that the model knows when it reads the stream when a new entry is beginning.\n",
        "\n",
        "So to recap, at every epoch we shuffle our collection of documents and concatenate them into a stream of tokens. We then cut that stream into a batch of fixed-size consecutive mini-streams. Our model will then read the mini-streams in order, and thanks to an inner state, it will produce the same activation whatever sequence length we picked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFn7DDePhOsD"
      },
      "source": [
        "This concludes all the preprocessing steps we need to apply to our data. We are now ready to train our text classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ6TgoHBhOsD"
      },
      "source": [
        "## Training a Text Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8la9YnoFhOsE"
      },
      "source": [
        "As we saw at the beginning of this chapter, there are two steps to training a state-of-the-art text classifier using transfer learning: first we need to fine-tune our language model pretrained on Wikipedia to our corpus, and then we can use that model to train a classifier.\n",
        "\n",
        "As usual, let's start with assembling our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ep6OrZhhOsF"
      },
      "source": [
        "### Language Model Using DataBlock"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emfy8-OVhOsG"
      },
      "source": [
        "fastai handles tokenization and numericalization automatically when `TextBlock` is passed to `DataBlock`. All of the arguments that can be passed to `Tokenize` and `Numericalize` can also be passed to `TextBlock`. In the next chapter we'll discuss the easiest ways to run each of these steps separately, to ease debugging—but you can always just debug by running them manually on a subset of your data as shown in the previous sections. And don't forget about `DataBlock`'s handy `summary` method, which is very useful for debugging data issues.\n",
        "\n",
        "Here's how we use `TextBlock` to create a language model, using fastai's defaults:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dls_lm = DataBlock(\n",
        "    blocks=TextBlock.from_df('book_desc', is_lm=True),get_x=ColReader('text'))\n",
        "\n",
        "dls_lm = dls_lm.dataloaders(df, bs=64)\n",
        "dls_lm.show_batch(max_n=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "a_CKie2fQ2uD",
        "outputId": "73e4baa1-f96e-458d-ca09-8e926c7eff05"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos xxmaj in this iridescent gem of a novel , xxmaj louis de xxmaj xxunk returns to the territory he mapped so well in xxmaj the xxmaj war of xxmaj don xxmaj emmanuel 's xxmaj nether xxmaj parts , a xxmaj south xxmaj american country of resplendent eccentricity , gargantuan corruption , and terrifying violence , where the ordinary machinery of government has rusted and the only thing that works is magic</td>\n",
              "      <td>xxmaj in this iridescent gem of a novel , xxmaj louis de xxmaj xxunk returns to the territory he mapped so well in xxmaj the xxmaj war of xxmaj don xxmaj emmanuel 's xxmaj nether xxmaj parts , a xxmaj south xxmaj american country of resplendent eccentricity , gargantuan corruption , and terrifying violence , where the ordinary machinery of government has rusted and the only thing that works is magic .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>amaranth , is seen through the eyes of an aging and sick warrior , xxmaj admiral xxmaj julian xxmaj stansfield , as he carries the weight of his country on his shoulders . xxmaj handicapped by personal grief and medical illness , he directs the xxmaj united xxmaj states through a major conventional world war . xxmaj he worries for his three sons who are all scattered around the planet in their</td>\n",
              "      <td>, is seen through the eyes of an aging and sick warrior , xxmaj admiral xxmaj julian xxmaj stansfield , as he carries the weight of his country on his shoulders . xxmaj handicapped by personal grief and medical illness , he directs the xxmaj united xxmaj states through a major conventional world war . xxmaj he worries for his three sons who are all scattered around the planet in their respective</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl8f7mOAhOsJ"
      },
      "source": [
        "Now that our data is ready, we can fine-tune the pretrained language model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8OZ89OqhOsK"
      },
      "source": [
        "### Fine-Tuning the Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szS8F_URhOsK"
      },
      "source": [
        "To convert the integer word indices into activations that we can use for our neural network, we will use embeddings, just like we did for collaborative filtering and tabular modeling. Then we'll feed those embeddings into a *recurrent neural network* (RNN), using an architecture called *AWD-LSTM*. As we discussed earlier, the embeddings in the pretrained model are merged with random embeddings added for words that weren't in the pretraining vocabulary. This is handled automatically inside `language_model_learner`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "hVueQpbnhOsL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "33ed2368-9cb2-4082-9378-2ff678485c14"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='105070592' class='' max='105067061' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [105070592/105067061 00:02<00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "learn = language_model_learner(\n",
        "    dls_lm, AWD_LSTM, drop_mult=0.3, \n",
        "    metrics=[accuracy, Perplexity()]).to_fp16()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypXTnv_whOsM"
      },
      "source": [
        "The loss function used by default is cross-entropy loss, since we essentially have a classification problem (the different categories being the words in our vocab). The *perplexity* metric used here is often used in NLP for language models: it is the exponential of the loss (i.e., `torch.exp(cross_entropy)`). We  also include the accuracy metric, to see how many times our model is right when trying to predict the next word, since cross-entropy (as we've seen) is both hard to interpret, and tells us more about the model's confidence than its accuracy.\n",
        "\n",
        "Let's go back to the process diagram from the beginning of this chapter. The first arrow has been completed for us and made available as a pretrained model in fastai, and we've just built the `DataLoaders` and `Learner` for the second stage. Now we're ready to fine-tune our language model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOqdgNzPhOsN"
      },
      "source": [
        "It takes quite a while to train each epoch, so we'll be saving the intermediate model results during the training process. Since `fine_tune` doesn't do that for us, we'll use `fit_one_cycle`. Just like `vision_learner`, `language_model_learner` automatically calls `freeze` when using a pretrained model (which is the default), so this will only train the embeddings (the only part of the model that contains randomly initialized weights—i.e., embeddings for words that are in our own vocab, but aren't in the pretrained model vocab):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "ioICh4OIhOsN",
        "outputId": "2ca93b4c-9e34-4ac7-84e1-63b66b42be8e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.112721</td>\n",
              "      <td>3.988225</td>\n",
              "      <td>0.308627</td>\n",
              "      <td>53.959015</td>\n",
              "      <td>16:20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Train for one cycle only for the randomly initialized weights (words that are not in the pretrained model)\n",
        "learn.fit_one_cycle(1, 2e-2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nqnYHaKhOsO"
      },
      "source": [
        "### Saving and Loading Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l38IGsdshOsO"
      },
      "source": [
        "You can easily save the state of your model like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF5k3QTohOsP",
        "outputId": "8763ba34-4a3f-45dc-a4e6-38a32d364c6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/content/gdrive/MyDrive/NLP/1epoch.pth')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "learn.save('/content/gdrive/MyDrive/NLP/1epoch')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwW4mY4EhOsP"
      },
      "source": [
        "This will create a file named *1epoch.pth*. If you want to load your model in another machine after creating your `Learner` the same way, or resume training later, you can load the content of this file with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Cb8jKftJhOsP"
      },
      "outputs": [],
      "source": [
        "learn = learn.load('/content/gdrive/MyDrive/NLP/1epoch')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twsOguwHhOsQ"
      },
      "source": [
        "Once the initial training has completed, we can continue fine-tuning the model after unfreezing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "klPIvk1vhOsQ",
        "outputId": "b3536edc-36c5-49f0-d609-3f63411a8d00"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.737280</td>\n",
              "      <td>3.859213</td>\n",
              "      <td>0.325504</td>\n",
              "      <td>47.428028</td>\n",
              "      <td>16:56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.685014</td>\n",
              "      <td>3.810924</td>\n",
              "      <td>0.330890</td>\n",
              "      <td>45.192158</td>\n",
              "      <td>17:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.570149</td>\n",
              "      <td>3.761614</td>\n",
              "      <td>0.337602</td>\n",
              "      <td>43.017784</td>\n",
              "      <td>17:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.411179</td>\n",
              "      <td>3.748586</td>\n",
              "      <td>0.341668</td>\n",
              "      <td>42.460987</td>\n",
              "      <td>16:57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.280570</td>\n",
              "      <td>3.750224</td>\n",
              "      <td>0.345136</td>\n",
              "      <td>42.530613</td>\n",
              "      <td>17:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.104637</td>\n",
              "      <td>3.752321</td>\n",
              "      <td>0.348173</td>\n",
              "      <td>42.619869</td>\n",
              "      <td>17:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.925128</td>\n",
              "      <td>3.771851</td>\n",
              "      <td>0.349610</td>\n",
              "      <td>43.460419</td>\n",
              "      <td>17:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.770674</td>\n",
              "      <td>3.802989</td>\n",
              "      <td>0.350138</td>\n",
              "      <td>44.835018</td>\n",
              "      <td>17:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.671160</td>\n",
              "      <td>3.825079</td>\n",
              "      <td>0.349861</td>\n",
              "      <td>45.836411</td>\n",
              "      <td>17:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.587893</td>\n",
              "      <td>3.842176</td>\n",
              "      <td>0.349316</td>\n",
              "      <td>46.626823</td>\n",
              "      <td>17:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(10, 2e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cae0tiQihOsR"
      },
      "source": [
        "Once this is done, we save all of our model except the final layer that converts activations to probabilities of picking each token in our vocabulary. The model not including the final layer is called the *encoder*. We can save it with `save_encoder`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "RLLz1LQRhOsR"
      },
      "outputs": [],
      "source": [
        "learn.save_encoder('/content/gdrive/MyDrive/NLP/finetuned')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu5_WU81hOsR"
      },
      "source": [
        "> jargon: Encoder: The model not including the task-specific final layer(s). This term means much the same thing as _body_ when applied to vision CNNs, but \"encoder\" tends to be more used for NLP and generative models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P_l3-AkhOsR"
      },
      "source": [
        "This completes the second stage of the text classification process: fine-tuning the language model. We can now use it to fine-tune a classifier using the IMDb sentiment labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kWzv6yThOsU"
      },
      "source": [
        "### Creating the Classifier DataLoaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9akSfvO-hOsU"
      },
      "source": [
        "We're now moving from language model fine-tuning to classifier fine-tuning. To recap, a language model predicts the next word of a document, so it doesn't need any external labels. A classifier, however, predicts some external label.\n",
        "\n",
        "This means that the structure of our `DataBlock` for NLP classification will look very familiar. It's actually nearly the same as we've seen for the many image classification datasets we've worked with.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's crete from the rating the categorical variable for positive rating above 3.5 over 5 and negative below that."
      ],
      "metadata": {
        "id": "NAD5FrNGC-2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['book_rating'] = np.where(df['book_rating'] > 3.5, 'Pos', 'Neg')"
      ],
      "metadata": {
        "id": "Hd9KBpyfiEdx"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now create the data block for the classification task"
      ],
      "metadata": {
        "id": "2njxUfTYDHxG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "9iL824u6hOsU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "a61fce6c-58fc-481b-cd39-9b93069b41fc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos xxmaj spiritus xxmaj mundi by xxmaj robert xxmaj sheppard , nominated for the prestigious 2014 xxmaj pushcart xxmaj prize for xxmaj literature , consists of xxmaj spiritus xxmaj mundi , the novel — book xxup i , and xxmaj spiritus xxmaj mundi , the romance — book xxup ii . xxmaj book xxmaj i ’s espionage - terror - political - religious thriller - action criss - crosses the globe from xxmaj beijing to xxmaj london to xxmaj washington , xxmaj mexico xxmaj city and xxmaj jerusalem presenting a vast panorama of the contemporary international world , including compelling action , deep and realistic characters and surreal adventures , while xxmaj book xxup ii xxunk the setting and scope into a fantasy ( though still rooted in the real ) adventure where the protagonists embark on a quest to the realms of xxmaj middle xxmaj earth and its xxmaj</td>\n",
              "      <td>Pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xxbos xxmaj home is where the heart is … . xxmaj five authors , five tales spanning centuries all set in the same mansion on the water … \\t xxmaj to some of us , home is everything . xxmaj our connection to the past , a place in which to build a future , the only place to run when the world we know falls apart … . \\t xxmaj for xxmaj livie xxmaj harrington , xxmaj bliss is everything . xxmaj it ’s a house comprised of memories , the last remaining link to her past . xxmaj in a life shattered by the war between the states , xxmaj bliss becomes xxmaj livie ’s anchor , the driving force behind her desperate scramble to rebuild a lost family fortune . xxmaj she ’s lost her parents , her only love , and her brother is off fighting</td>\n",
              "      <td>Pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "imdb_clas = DataBlock(\n",
        "    blocks=(TextBlock.from_df('book_desc', seq_len=72,vocab=dls_lm.vocab), CategoryBlock),\n",
        "    get_x=ColReader('text'), get_y=ColReader('book_rating'))\n",
        "\n",
        "dls_clas = imdb_clas.dataloaders(df, bs=64)\n",
        "dls_clas.show_batch(max_n=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We validate that the vocabulary of the language model and the downstream task model is the same:"
      ],
      "metadata": {
        "id": "_Ml0m4kHDQBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(dls_clas.vocab[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPeScYFFnh2o",
        "outputId": "9213ad19-2583-47ad-f0f1-bb71e6fa59db"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51296"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dls_lm.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDhmeCk2n_CY",
        "outputId": "9c7475b6-e20f-47f4-f4ad-2addabca6102"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51296"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZlJ_r4chOsY"
      },
      "source": [
        "Looking at the `DataBlock` definition, every piece is familiar from previous data blocks we've built, with two important exceptions:\n",
        "\n",
        "- `TextBlock.from_df` no longer has the `is_lm=True` parameter.\n",
        "- We pass the `vocab` we created for the language model fine-tuning.\n",
        "\n",
        "The reason that we pass the `vocab` of the language model is to make sure we use the same correspondence of token to index. Otherwise the embeddings we learned in our fine-tuned language model won't make any sense to this model, and the fine-tuning step won't be of any use.\n",
        "\n",
        "By passing `is_lm=False` (or not passing `is_lm` at all, since it defaults to `False`) we tell `TextBlock` that we have regular labeled data, rather than using the next tokens as labels. There is one challenge we have to deal with, however, which is to do with collating multiple documents into a mini-batch. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AIKXyRJhOsZ"
      },
      "source": [
        "Remember, PyTorch `DataLoader`s need to collate all the items in a batch into a single tensor, and a single tensor has a fixed shape (i.e., it has some particular length on every axis, and all items must be consistent). This should sound familiar: we had the same issue with images. In that case, we use padding as cropping and other augmentation do not make sense!\n",
        "\n",
        "We will expand the shortest texts to make them all the same size. To do this, we use a special padding token that will be ignored by our model. Additionally, to avoid memory issues and improve performance, we will batch together texts that are roughly the same lengths (with some shuffling for the training set). We do this by (approximately, for the training set) sorting the documents by length prior to each epoch. The result of this is that the documents collated into a single batch will tend to be of similar lengths. We won't pad every batch to the same size, but will instead use the size of the largest document in each batch as the target size. \n",
        "\n",
        "The sorting and padding are automatically done by the data block API for us when using a `TextBlock`, with `is_lm=False`. (We don't have this same issue for language model data, since we concatenate all the documents together first, and then split them into equally sized sections.)\n",
        "\n",
        "We can now create a model to classify our texts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "vGE0DNdYhOsa"
      },
      "outputs": [],
      "source": [
        "learn = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.5, \n",
        "                                metrics=accuracy).to_fp16()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-V0lEZphOsb"
      },
      "source": [
        "The final step prior to training the classifier is to load the encoder from our fine-tuned language model. We use `load_encoder` instead of `load` because we only have pretrained weights available for the encoder; `load` by default raises an exception if an incomplete model is loaded:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Fn2EfZUXhOsb"
      },
      "outputs": [],
      "source": [
        "learn = learn.load_encoder('/content/gdrive/MyDrive/NLP/finetuned')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9mHZhqPhOsc"
      },
      "source": [
        "### Fine-Tuning the Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvVw3xflhOsc"
      },
      "source": [
        "The last step is to train with discriminative learning rates and *gradual unfreezing*. In computer vision we often unfreeze the model all at once, but for NLP classifiers, we find that unfreezing a few layers at a time makes a real difference:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn.lr_find()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "VRJZXLBUhOl3",
        "outputId": "254952bb-304b-40ba-a085-242ce51370f1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(valley=0.019054606556892395)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "L7_BxMIfhOsc",
        "outputId": "5efbc475-4968-4be1-ce57-4af496a65b14"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.178490</td>\n",
              "      <td>0.194537</td>\n",
              "      <td>0.950228</td>\n",
              "      <td>01:28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "learn.fit_one_cycle(1, 0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCp3ksqmhOsd"
      },
      "source": [
        "In just one epoch we get the same result as our training in <<chapter_intro>>: not too bad! We can pass `-2` to `freeze_to` to freeze all except the last two parameter groups:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "6FEn3wkBhOsd",
        "outputId": "35bbc07c-eb34-48c9-be07-2f2de91a2b0b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.170722</td>\n",
              "      <td>0.188280</td>\n",
              "      <td>0.950554</td>\n",
              "      <td>01:43</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(1, slice(0.001/(2.6**4),0.001))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrfHhXKnhOsf"
      },
      "source": [
        "And finally, the whole model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "VKwqcf9hhOsf",
        "outputId": "8f5b661f-f9c5-47c2-b31f-b19866cbacec"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.169639</td>\n",
              "      <td>0.188118</td>\n",
              "      <td>0.950011</td>\n",
              "      <td>03:10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(1, slice(0.001/(2.6**4),0.001))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_btQrIrhOsg"
      },
      "source": [
        "We reached 95% accuracy, which is surprising as we are using only book description, is really interesting that it was able to find which books will have very high and low review. \n",
        "\n",
        "Using a pretrained model let us build a fine-tuned language model that was pretty powerful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtDx3-ouhOsi"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPmc8EFuhOsj"
      },
      "source": [
        "In this chapter we explored the last application covered out of the box by the fastai library: text. We saw  language models that can be used and fine tuned to any downstream task. To build a state-of-the art classifier, we used a pretrained language model, fine-tuned it to the corpus of our task, then used its body (the encoder) with a new head to do the classification.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "split_at_heading": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "10_nlp.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}